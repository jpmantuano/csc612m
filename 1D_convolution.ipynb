{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpmantuano/csc612m/blob/main/1D_convolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OSKWXSS9QZio"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WFMbYN2lQZlM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FITVbvx8QZn1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CUDA Programming Project Specifications : 1D Convolution ###"
      ],
      "metadata": {
        "id": "NzHn8HyuOkc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implements a 1D convolution and compares the performance of CPU-based and GPU-accelerated CUDA implementations, exploring different data transfer methods and CUDA optimization techniques."
      ],
      "metadata": {
        "id": "mj5vCVWckj-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implementation of the 1D convolution defined as : out[i] = (in[i] + in[i + 1] + in[i + 2]) / 3.0f ####\n",
        "\n",
        "\n",
        "```\n",
        "__global__ void conv1D_kernel(const float* in, float* out, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n - 2) {[link text](https://)\n",
        "        out[i] = (in[i] + in[i + 1] + in[i + 2]) / 3.0f;\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "1-N_S0puOkhu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Input: `2^28` elements or `268435456` ####\n",
        "It is initialized using the following code:\n",
        "\n",
        "\n",
        "```\n",
        "float* initialize_input(float *in, size_t n) {\n",
        "    for (size_t i = 0; i < n; i++) {\n",
        "        in[i] = (float)i;\n",
        "    }\n",
        "    return in;\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "I70Ynx5OOkfG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first and last 20 elements of the output with be displayed at the end of the run, excluding the two zeros at the end.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "void print_results(const float *out, size_t n) {\n",
        "    printf(\"First %d elements of output:\\n\", PRINT_VALUES);\n",
        "    for (int i = 0; i < PRINT_VALUES; i++) {\n",
        "        printf(\"out[%d] = %f\\n\", i, out[i]);\n",
        "    }\n",
        "\n",
        "    printf(\"Last %d elements of output:\\n\", PRINT_VALUES);\n",
        "    for (size_t i = n - PRINT_VALUES; i < n - 2; i++) {\n",
        "        printf(\"out[%zu] = %f\\n\", i, out[i]);\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Ktwq_DImOkkN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The convolution method will be run 30 times and the average runtime will be recorded, this is to accomodate any forms of caching and inconsistencies between runs.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "//Kernel run method\n",
        "void run_kernel(const float *in, float *out) {\n",
        "    int blocks = (N + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;\n",
        "    for (int iter = 0; iter < RUNS; iter++) {\n",
        "        conv1D_kernel<<<blocks, THREADS_PER_BLOCK>>>(in, out, N);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "CPs3qqafQqw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Error checking method, also excluding the last two elements as they are always Zero.\n",
        "\n",
        "```\n",
        "size_t check_errors(const float *in, const float *out, size_t n) {\n",
        "    size_t err_count = 0;\n",
        "    for (size_t i = 0; i < n - 2; i++) {\n",
        "        float expected = (in[i] + in[i + 1] + in[i + 2]) / 3.0f;\n",
        "        if (fabs(out[i] - expected) > 1e-5) {\n",
        "            err_count++;\n",
        "        }\n",
        "    }\n",
        "    return err_count;\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Bi20MIPsQq9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MOTYpQzJQrAL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "706PvPER5rp3"
      },
      "source": [
        "###Using C to implement 1D Convolution ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1raDGvnQ5rs5"
      },
      "source": [
        "Get the runtime of 1D Convolution implemented in C and use as the baseline for comparison with the different CUDA version implementation of 1D Convolution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4mRXtzI5rvg"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlF1-qFE5qP5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbe1f9f3-4100-49fa-eeeb-babf45351796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting convolve1D.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile convolve1D.cpp\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <ctime>\n",
        "#include <cstdio>\n",
        "#include <cmath>\n",
        "\n",
        "void convolve1D(const std::vector<float>& in, std::vector<float>& out) {\n",
        "    int n = in.size();\n",
        "    if (n < 3) {\n",
        "        out.clear();\n",
        "        return;\n",
        "    }\n",
        "    out.resize(n - 2);\n",
        "    for (int i = 0; i < n - 2; ++i) {\n",
        "        out[i] = (in[i] + in[i + 1] + in[i + 2]) / 3.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Function to check errors between expected and actual output\n",
        "size_t check_errors(const std::vector<float>& in, const std::vector<float>& out) {\n",
        "    size_t err_count = 0;\n",
        "    int n = static_cast<int>(in.size());\n",
        "    if (out.size() != n - 2) {\n",
        "        std::cerr << \"Output size mismatch: expected \" << n - 2 << \", got \" << out.size() << std::endl;\n",
        "        return static_cast<size_t>(-1); // Indicate size mismatch error\n",
        "    }\n",
        "    for (int i = 0; i < n - 2; ++i) {\n",
        "        float expected = (in[i] + in[i + 1] + in[i + 2]) / 3.0f;\n",
        "        if (std::fabs(out[i] - expected) > 1e-5f) {\n",
        "            err_count++;\n",
        "        }\n",
        "    }\n",
        "    return err_count;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 268435456;\n",
        "    int runs = 30;\n",
        "\n",
        "    std::vector<float> _in_(N);\n",
        "\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "      _in_[i] = static_cast<float>(i + 1);\n",
        "    }\n",
        "\n",
        "    std::vector<float> _out_;\n",
        "\n",
        "    clock_t start, end;\n",
        "    double cpu_time_used;\n",
        "    double sum = 0.0;\n",
        "\n",
        "    for (int run = 0; run < runs; run++) {\n",
        "      start = clock();  // Start time\n",
        "      convolve1D(_in_, _out_);\n",
        "      end = clock(); // End time\n",
        "\n",
        "      cpu_time_used = ((double) (end - start)) / CLOCKS_PER_SEC;\n",
        "      sum += cpu_time_used;\n",
        "    }\n",
        "\n",
        "    // Check for errors\n",
        "    size_t err_count = check_errors(_in_, _out_);\n",
        "    if (err_count == static_cast<size_t>(-1)) {\n",
        "        std::cerr << \"Error: Output size mismatch.\" << std::endl;\n",
        "    } else if (err_count > 0) {\n",
        "        std::cerr << \"Error count: \" << err_count << \" mismatches found in output.\" << std::endl;\n",
        "    } else {\n",
        "        std::cout << \"Output verification passed: no errors found.\" << std::endl;\n",
        "    }\n",
        "\n",
        "    double avg_time = sum / runs;\n",
        "    printf(\"Average execution time for %d inputs: %.6f seconds\\n\", 2^28, avg_time);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYs6sSns5qSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c774586-dbe5-41e2-9bb9-6d04da4d33bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "%%shell\n",
        "g++ -o convolve1D convolve1D.cpp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5CXskI15qVC",
        "outputId": "bddeb6b8-a88c-4712-86ae-8bb97e7c552b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output verification passed: no errors found.\n",
            "Average execution time for 30 inputs: 3.134053 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "%%shell\n",
        "./convolve1D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLe-9xwX8OGO"
      },
      "source": [
        "### Check if CUDA is present ###"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting the GPU id for Google Colab but this is often 0 for free tier accounts."
      ],
      "metadata": {
        "id": "3G_UyT1RSBJp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLT2S64X8OqZ"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53Q0_dXs36-_"
      },
      "source": [
        "### Unified memory ###"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A single memory address space accessible by both CPU and GPU. [Nvidia Blog](https://developer.nvidia.com/blog/unified-memory-cuda-beginners/)"
      ],
      "metadata": {
        "id": "GoprbljUWXJ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Features\n",
        "\n",
        "* Simplifies memory management with cudaMallocManaged() instead of separate allocations1.\n",
        "\n",
        "* Automatic page migration handles data movement between host and device1.\n",
        "\n",
        "* Eliminates manual cudaMemcpy calls for basic use cases."
      ],
      "metadata": {
        "id": "dF1Kok6iWjtn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example:\n",
        "\n",
        "```\n",
        "float *data;\n",
        "cudaMallocManaged(&data, N * sizeof(float));  // Accessible by CPU/GPU\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "TE89D2u8ZMxR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1A7y-4LT6FA"
      },
      "outputs": [],
      "source": [
        "%%writefile method_unified_memory.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <math.h>\n",
        "\n",
        "#define N 268435456\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "#define RUNS 30\n",
        "#define PRINT_VALUES 20\n",
        "\n",
        "__global__ void conv1D_kernel(const float* in, float* out, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n - 2) {\n",
        "        out[i] = (in[i] + in[i + 1] + in[i + 2]) / 3.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "void initialize_input(float *in, size_t n) {\n",
        "    for (size_t i = 0; i < n; i++) {\n",
        "        in[i] = (float)i;\n",
        "    }\n",
        "}\n",
        "\n",
        "void run_kernel_multiple_times(const float *in, float *out) {\n",
        "    int blocks = (N + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;\n",
        "    for (int iter = 0; iter < RUNS; iter++) {\n",
        "        conv1D_kernel<<<blocks, THREADS_PER_BLOCK>>>(in, out, N);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "}\n",
        "\n",
        "void print_results(const float *out, size_t n) {\n",
        "    printf(\"First %d elements of output:\\n\", PRINT_VALUES);\n",
        "    for (int i = 0; i < PRINT_VALUES; i++) {\n",
        "        printf(\"out[%d] = %f\\n\", i, out[i]);\n",
        "    }\n",
        "\n",
        "    printf(\"Last %d elements of output:\\n\", PRINT_VALUES);\n",
        "    for (size_t i = N - 20; i < N - 2; i++) {\n",
        "        printf(\"out[%zu] = %f\\n\", i, out[i]);\n",
        "    }\n",
        "}\n",
        "\n",
        "size_t check_errors(const float *in, const float *out, size_t n) {\n",
        "    size_t err_count = 0;\n",
        "    for (size_t i = 0; i < n - 2; i++) {\n",
        "        float expected = (in[i] + in[i + 1] + in[i + 2]) / 3.0f;\n",
        "        if (fabs(out[i] - expected) > 1e-5) {\n",
        "            err_count++;\n",
        "        }\n",
        "    }\n",
        "    return err_count;\n",
        "}\n",
        "\n",
        "void method_unified_memory(float *in, float *out, size_t n) {\n",
        "    run_kernel_multiple_times(in, out);\n",
        "\n",
        "    print_results(out, n);\n",
        "\n",
        "    size_t err_count = check_errors(in, out, n);\n",
        "    printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float *in = NULL;\n",
        "    float *out = NULL;\n",
        "\n",
        "    cudaMallocManaged(&in, N * sizeof(float));\n",
        "    cudaMallocManaged(&out, N * sizeof(float));\n",
        "\n",
        "    initialize_input(in, N);\n",
        "\n",
        "    method_unified_memory(in, out, N);\n",
        "\n",
        "    cudaFree(in);\n",
        "    cudaFree(out);\n",
        "\n",
        "    printf(\"\\n\");\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edu7o7rEHR51"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "nvcc method_unified_memory.cu -o method_unified_memory -arch=sm_75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3oalq7qHR9d"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "./method_unified_memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZzWISFXH-25"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "nvprof ./method_unified_memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sdDBGNI4FzK"
      },
      "source": [
        "### Prefetching data with Memory Advice ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "249J-6yb4F1z"
      },
      "source": [
        "Explicit control over data locality using:\n",
        "\n",
        "**a. cudaMemPrefetchAsync**\n",
        "\n",
        "Pre-migrates data to a specific processor (CPU/GPU) before access:\n",
        "\n",
        "```\n",
        "cudaMemPrefetchAsync(data, size, deviceId);  // Force data to GPU\n",
        "\n",
        "```\n",
        "**b. cudaMemAdvise**\n",
        "\n",
        "Hints about access patterns:\n",
        "```\n",
        "cudaMemAdvise(data, size, cudaMemAdviseSetAccessedBy, deviceId);  // GPU will access\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN6e3dKQ4F4p"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaunkR7wMbc0"
      },
      "outputs": [],
      "source": [
        "%%writefile method_prefetching_memory_advice.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <math.h>\n",
        "\n",
        "#define N 268435456\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "#define RUNS 30\n",
        "#define VALUES 20\n",
        "\n",
        "__global__ void conv1D_kernel(const float* in, float* out, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n - 2) {\n",
        "        out[i] = (in[i] + in[i + 1] + in[i + 2]) / 3.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "void allocate_managed_memory(float **in, float **out) {\n",
        "    cudaMallocManaged(in, N * sizeof(float));\n",
        "    cudaMallocManaged(out, N * sizeof(float));\n",
        "}\n",
        "\n",
        "void set_memory_advice(float *in, float *out) {\n",
        "    cudaMemAdvise(in, N * sizeof(float), cudaMemAdviseSetPreferredLocation, 0);\n",
        "    cudaMemAdvise(out, N * sizeof(float), cudaMemAdviseSetPreferredLocation, 0);\n",
        "}\n",
        "\n",
        "void initialize_input(float *in) {\n",
        "    for (size_t i = 0; i < N; i++) {\n",
        "        in[i] = (float)i;\n",
        "    }\n",
        "}\n",
        "\n",
        "void prefetch_to_device(float *in, float *out) {\n",
        "    cudaMemPrefetchAsync(in, N * sizeof(float), 0);\n",
        "    cudaMemPrefetchAsync(out, N * sizeof(float), 0);\n",
        "    cudaDeviceSynchronize();\n",
        "}\n",
        "\n",
        "void run_kernel_multiple_times(const float *in, float *out) {\n",
        "    int blocks = (N + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;\n",
        "    for (int iter = 0; iter < RUNS; iter++) {\n",
        "        conv1D_kernel<<<blocks, THREADS_PER_BLOCK>>>(in, out, N);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "}\n",
        "\n",
        "void prefetch_to_host(float *out) {\n",
        "    cudaMemPrefetchAsync(out, N * sizeof(float), cudaCpuDeviceId);\n",
        "    cudaDeviceSynchronize();\n",
        "}\n",
        "\n",
        "void print_results(const float *out) {\n",
        "    printf(\"First %d elements of output:\\n\", VALUES);\n",
        "    for (int i = 0; i < VALUES; i++) {\n",
        "        printf(\"out[%d] = %f\\n\", i, out[i]);\n",
        "    }\n",
        "\n",
        "    printf(\"Last %d elements of output:\\n\", VALUES);\n",
        "    for (int i = N - VALUES; i < N - 2; i++) {\n",
        "        printf(\"out[%d] = %f\\n\", i, out[i]);\n",
        "    }\n",
        "}\n",
        "\n",
        "void check_errors(const float *in, const float *out) {\n",
        "    size_t err_count = 0;\n",
        "    for (size_t i = 0; i < N-2; i++) {\n",
        "        float expected = (in[i] + in[i + 1] + in[i + 2]) / 3.0f;\n",
        "        if (fabs(out[i] - expected) > 1e-5) {\n",
        "            err_count++;\n",
        "        }\n",
        "    }\n",
        "    printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
        "}\n",
        "\n",
        "void cleanup(float *in, float *out) {\n",
        "    cudaFree(in);\n",
        "    cudaFree(out);\n",
        "}\n",
        "\n",
        "void method_prefetching_memory_advice() {\n",
        "    float *in = NULL, *out = NULL;\n",
        "\n",
        "    allocate_managed_memory(&in, &out);\n",
        "    set_memory_advice(in, out);\n",
        "    initialize_input(in);\n",
        "    prefetch_to_device(in, out);\n",
        "    run_kernel_multiple_times(in, out);\n",
        "    prefetch_to_host(out);\n",
        "    print_results(out);\n",
        "    check_errors(in, out);\n",
        "    cleanup(in, out);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    method_prefetching_memory_advice();\n",
        "    printf(\"\\n\");\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbbS_cmx47q1"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "nvcc method_prefetching_memory_advice.cu -o method_prefetching_memory_advice -arch=sm_75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvMmiS9R47tU"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "./method_prefetching_memory_advice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Qegh_YOF47v9"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "nvprof ./method_prefetching_memory_advice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DQBpuAR4QxY"
      },
      "source": [
        "### Data initialization as a CUDA kernel ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaffN5DP4Q0I"
      },
      "source": [
        "Direct GPU-side initialization avoids host-device transfers:\n",
        "\n",
        "**Advantages**\n",
        "\n",
        "* Eliminates cudaMemcpy for initial data setup.\n",
        "\n",
        "* Faster for large datasets (no PCIe transfer).\n",
        "\n",
        "Example:\n",
        "```\n",
        "__global__ void init_kernel(float *data, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) data[i] = i;  // Initialize directly on GPU\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bicGPHG4Q3C"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile method_init_data_kernel.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <math.h>\n",
        "\n",
        "#define N 268435456\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "#define RUNS 30\n",
        "#define VALUES 20\n",
        "\n",
        "// CUDA kernel: 1D convolution averaging 3 elements\n",
        "__global__ void conv1D_kernel(const float* in, float* out, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n - 2) {\n",
        "        out[i] = (in[i] + in[i + 1] + in[i + 2]) / 3.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "// CUDA kernel: initialize data on device with index values\n",
        "__global__ void init_data_kernel(float* data, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        data[i] = (float)i;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Allocate unified memory for input and output arrays\n",
        "void allocate_memory(float** in, float** out, size_t size) {\n",
        "    cudaMallocManaged((void**)in, size);\n",
        "    cudaMallocManaged((void**)out, size);\n",
        "}\n",
        "\n",
        "// Free allocated unified memory\n",
        "void free_memory(float* in, float* out) {\n",
        "    cudaFree(in);\n",
        "    cudaFree(out);\n",
        "}\n",
        "\n",
        "// Launch kernel to initialize input data on GPU\n",
        "void initialize_data(float* in, int n, int blocks) {\n",
        "    init_data_kernel<<<blocks, THREADS_PER_BLOCK>>>(in, n);\n",
        "    cudaDeviceSynchronize();\n",
        "}\n",
        "\n",
        "// Launch kernel to perform 1D convolution\n",
        "void perform_convolution(const float* in, float* out, int n, int blocks) {\n",
        "    for (int iter = 0; iter < RUNS; iter++) {\n",
        "        conv1D_kernel<<<blocks, THREADS_PER_BLOCK>>>(in, out, N);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "}\n",
        "\n",
        "// Print first and last 20 elements of output array\n",
        "void print_results(const float* out, int n) {\n",
        "    int i;\n",
        "    printf(\"First 20 elements of output:\\n\");\n",
        "    for (i = 0; i < 20; i++) {\n",
        "        printf(\"out[%d] = %f\\n\", i, out[i]);\n",
        "    }\n",
        "\n",
        "    printf(\"Last 20 elements of output:\\n\");\n",
        "    for (i = n - 20; i < n - 2; i++) {\n",
        "        printf(\"out[%d] = %f\\n\", i, out[i]);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Check for errors comparing output with expected values\n",
        "size_t check_errors(const float* in, const float* out, int n) {\n",
        "    size_t err_count = 0;\n",
        "    int i;\n",
        "    for (i = 0; i < n - 2; i++) {\n",
        "        float expected = (in[i] + in[i + 1] + in[i + 2]) / 3.0f;\n",
        "        if (fabsf(out[i] - expected) > 1e-5f) {\n",
        "            err_count++;\n",
        "        }\n",
        "    }\n",
        "    return err_count;\n",
        "}\n",
        "\n",
        "void method_init_data_kernel() {\n",
        "    float *in = NULL, *out = NULL;\n",
        "    size_t size = N * sizeof(float);\n",
        "    allocate_memory(&in, &out, size);\n",
        "\n",
        "    int blocks = (N + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;\n",
        "\n",
        "    initialize_data(in, N, blocks);\n",
        "    perform_convolution(in, out, N, blocks);\n",
        "\n",
        "    print_results(out, N);\n",
        "\n",
        "    size_t err_count = check_errors(in, out, N);\n",
        "    printf(\"Error count (CUDA program): %zu\\n\", err_count);\n",
        "\n",
        "    free_memory(in, out);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    method_init_data_kernel();\n",
        "    printf(\"\\n\");\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "R0CC7OVF9AL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qlctn7QV4_Dp"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "nvcc method_init_data_kernel.cu -o method_init_data_kernel -arch=sm_75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4VgIRRA4_GE"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "nvprof ./method_init_data_kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vowRPWD04_Iy"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "./method_init_data_kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IshL_wim4Y8J"
      },
      "source": [
        "### Old method of data transfer ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcVdMWuO4Y-b"
      },
      "source": [
        "Explicit host/device memory management:\n",
        "\n",
        "**Steps**\n",
        "\n",
        "1. Allocate host memory (malloc).\n",
        "2. Allocate device memory (cudaMalloc).\n",
        "3. Copy data:\n",
        "```\n",
        "cudaMemcpy(d_in, h_in, size, cudaMemcpyHostToDevice);  // Host→Device[6][7]\n",
        "```\n",
        "4. Process on GPU.\n",
        "5. Copy results back:\n",
        "```\n",
        "cudaMemcpy(h_out, d_out, size, cudaMemcpyDeviceToHost);  // Device→Host[6][7]\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8aoEc1m4ZBK"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile method_old_transfer.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <math.h>\n",
        "\n",
        "#define N 268435456\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "\n",
        "// CUDA kernel: 1D convolution averaging 3 elements\n",
        "__global__ void conv1D_kernel(const float* in, float* out, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n - 2) {\n",
        "        out[i] = (in[i] + in[i + 1] + in[i + 2]) / 3.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Allocate host memory for input and output arrays\n",
        "void allocate_host_memory(float** h_in, float** h_out, size_t size) {\n",
        "    *h_in = (float*)malloc(size);\n",
        "    *h_out = (float*)malloc(size);\n",
        "    if (*h_in == NULL || *h_out == NULL) {\n",
        "        fprintf(stderr, \"Failed to allocate host memory\\n\");\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Free host memory\n",
        "void free_host_memory(float* h_in, float* h_out) {\n",
        "    free(h_in);\n",
        "    free(h_out);\n",
        "}\n",
        "\n",
        "// Initialize input data on host\n",
        "void initialize_host_data(float* h_in, int n) {\n",
        "    int i;\n",
        "    for (i = 0; i < n; i++) {\n",
        "        h_in[i] = (float)i;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Allocate device memory for input and output arrays\n",
        "void allocate_device_memory(float** d_in, float** d_out, size_t size) {\n",
        "    cudaError_t err;\n",
        "    err = cudaMalloc((void**)d_in, size);\n",
        "    if (err != cudaSuccess) {\n",
        "        fprintf(stderr, \"cudaMalloc d_in failed: %s\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "    err = cudaMalloc((void**)d_out, size);\n",
        "    if (err != cudaSuccess) {\n",
        "        fprintf(stderr, \"cudaMalloc d_out failed: %s\\n\", cudaGetErrorString(err));\n",
        "        cudaFree(*d_in);\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Free device memory\n",
        "void free_device_memory(float* d_in, float* d_out) {\n",
        "    cudaFree(d_in);\n",
        "    cudaFree(d_out);\n",
        "}\n",
        "\n",
        "// Copy data from host to device\n",
        "void copy_host_to_device(float* d_in, float* h_in, size_t size) {\n",
        "    cudaMemcpy(d_in, h_in, size, cudaMemcpyHostToDevice);\n",
        "}\n",
        "\n",
        "// Copy data from device to host\n",
        "void copy_device_to_host(float* h_out, float* d_out, size_t size) {\n",
        "    cudaMemcpy(h_out, d_out, size, cudaMemcpyDeviceToHost);\n",
        "}\n",
        "\n",
        "// Launch convolution kernel\n",
        "void launch_convolution_kernel(const float* d_in, float* d_out, int n, int blocks) {\n",
        "    for (int iter = 0; iter < RUNS; iter++) {\n",
        "      conv1D_kernel<<<blocks, THREADS_PER_BLOCK>>>(d_in, d_out, n);\n",
        "      cudaDeviceSynchronize();\n",
        "    }\n",
        "}\n",
        "\n",
        "// Print first and last 20 elements of output array\n",
        "void print_results(const float* h_out, int n) {\n",
        "    int i;\n",
        "    printf(\"First 20 elements of output:\\n\");\n",
        "    for (i = 0; i < 20; i++) {\n",
        "        printf(\"h_out[%d] = %f\\n\", i, h_out[i]);\n",
        "    }\n",
        "\n",
        "    printf(\"Last 20 elements of output:\\n\");\n",
        "    for (i = n - 20; i < n - 2; i++) {\n",
        "        printf(\"h_out[%d] = %f\\n\", i, h_out[i]);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Check for errors comparing output with expected values\n",
        "size_t check_errors(const float* h_in, const float* h_out, int n) {\n",
        "    size_t err_count = 0;\n",
        "    int i;\n",
        "    for (i = 0; i < n - 2; i++) {\n",
        "        float expected = (h_in[i] + h_in[i + 1] + h_in[i + 2]) / 3.0f;\n",
        "        if (fabsf(h_out[i] - expected) > 1e-5f) {\n",
        "            err_count++;\n",
        "        }\n",
        "    }\n",
        "    return err_count;\n",
        "}\n",
        "\n",
        "// Main method encapsulating the workflow\n",
        "void method_old_transfer() {\n",
        "    printf(\"Method 4: Old Method with cudaMalloc + cudaMemcpy\\n\");\n",
        "\n",
        "    float *h_in = NULL, *h_out = NULL;\n",
        "    float *d_in = NULL, *d_out = NULL;\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    allocate_host_memory(&h_in, &h_out, size);\n",
        "    initialize_host_data(h_in, N);\n",
        "    allocate_device_memory(&d_in, &d_out, size);\n",
        "\n",
        "    copy_host_to_device(d_in, h_in, size);\n",
        "\n",
        "    int blocks = (N + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;\n",
        "    launch_convolution_kernel(d_in, d_out, N, blocks);\n",
        "\n",
        "    copy_device_to_host(h_out, d_out, size);\n",
        "\n",
        "    print_results(h_out, N);\n",
        "\n",
        "    size_t err_count = check_errors(h_in, h_out, N);\n",
        "    printf(\"Error count (CUDA program): %zu\\n\", err_count);\n",
        "\n",
        "    free_device_memory(d_in, d_out);\n",
        "    free_host_memory(h_in, h_out);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    method_old_transfer();\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "DPUeTgLo-1JI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Wh6wfWN3Ool"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "nvcc method_old_transfer.cu -o method_old_transfer -arch=sm_75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qa_ox_Ow3OrH"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "nvprof ./method_old_transfer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvvJvuCw3Otw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMdMjt563OwZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": [],
      "collapsed_sections": [
        "706PvPER5rp3",
        "XLe-9xwX8OGO",
        "53Q0_dXs36-_",
        "2sdDBGNI4FzK",
        "3DQBpuAR4QxY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}